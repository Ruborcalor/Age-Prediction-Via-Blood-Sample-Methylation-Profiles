# -*- coding: utf-8 -*-
"""Predicting Human Age via Blood DNA Methylation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TKirVZKApi72zS1ytHAjwnlDDbwOOjVQ

# Download Dataset
"""

# Get dataset. It's is too big to come as a single file
!wget -O "./GSE87571_Matrix_Avg_Beta.txt.gz" "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE87571&format=file&file=GSE87571%5Fmatrix1of2%2Etxt%2Egz"
!wget -O "./GSE87571_Matrix_Avg_Beta2.txt.gz" "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE87571&format=file&file=GSE87571%5Fmatrix2of2%2Etxt%2Egz"

# Extract dataset
!gunzip "./GSE87571_Matrix_Avg_Beta.txt.gz"
!gunzip "./GSE87571_Matrix_Avg_Beta2.txt.gz"

# Merge data set files into one
!cut -d$'\t' -f1 --complement "./GSE87571_Matrix_Avg_Beta2.txt" > newFile && mv newFile "./GSE87571_Matrix_Avg_Beta2.txt"
!paste "GSE87571_Matrix_Avg_Beta.txt" "./GSE87571_Matrix_Avg_Beta2.txt" > matrix.csv

# Remove every other column because every other column has blank values
!awk '{{printf "%s ", $1}for(i=2;i<=NF;i=i+2){printf "%s ", $i}{printf "%s", RS}}' matrix.csv > final_matrix.csv

# Get a sneak peak of the final output
!head -5 final_matrix.csv

"""# Imports"""

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries

import pandas as pd
import numpy as np
import random as rd
from sklearn.decomposition import PCA
from sklearn import preprocessing
import matplotlib.pyplot as plt # NOTE: This was tested with matplotlib v. 2.1.0
from sklearn.model_selection import train_test_split
from sklearn import metrics
import seaborn as sns

# import tensorflow

from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf

"""# Preprocessing"""

# Read data from txt file into dataframe
data = pd.read_csv("./final_matrix.csv", sep=' ', low_memory=False, index_col = 0)
data.drop("Unnamed: 733", inplace=True, axis=1)

# Add annotations from annotation file.
data_annotated = data.T

# read annotations
annotations = pd.read_csv("GSE87571_series_matrix.csv", index_col=0, header=None).T

for i, title in enumerate(annotations["Column_Name"]):
  annotations["Column_Name"][i + 1] = title[:title.index(" ")]

# Set index and remove unnecessary rows
annotations.set_index("Column_Name", inplace=True)
annotations.drop(["Tissue", "Disease"], axis=1, inplace=True)

# Format cells into float-ready strings
annotations['Gender'] = annotations['Gender'].str.replace('gender: ','')
annotations['Age'] = (annotations['Age'].str.replace('age: ',''))

# sort and merge
annotations.sort_index(inplace=True)
data_annotated.sort_index(inplace=True)
data_annotated = data_annotated.astype(float)
data_annotated["Age"] = annotations["Age"]

# dropna and set float
data_annotated.dropna(axis=1, inplace=True)
data_annotated = data_annotated[data_annotated.Age != "NA"]
data_annotated.Age = data_annotated.Age.astype(float)
print(data_annotated.shape)
print(data_annotated.head())

# Split data
train_annotated, test_annotated = train_test_split(data_annotated, test_size=0.10)

# Calculate correlation matrix
corr_array = []
for col in train_annotated.columns:
  corr_array.append(train_annotated[col].corr(train_annotated["Age"]))

print(len(corr_array))
corr_df = pd.DataFrame(corr_array, columns=["Correlation"], index=train_annotated.columns)

corr_df["Abs_Corr"] = corr_df.Correlation.abs()
corr_df.sort_values("Abs_Corr", inplace=True, ascending=False)
print(corr_df.head(26))
corr_df.to_csv("corr.csv")

# Transpose train_annotated and train_annotated
train_annotated = train_annotated.T
test_annotated = test_annotated.T

# Filter features by those with highest correlations in the training set

spots_select = corr_df.index[1:26].to_list()

train_processed = (train_annotated[train_annotated.index.isin(spots_select)]).T
test_processed = (test_annotated[test_annotated.index.isin(spots_select)]).T

print(train_processed)

# Visualize features in heatmap

# Sort features ascending by age in training and testing sets

train_processed = train_processed.assign(Age = train_annotated.T.Age)
train_processed = train_processed.sort_values("Age")
train_processed = train_processed.dropna(axis=0, how='any')

train_processed_ages = train_processed["Age"]
train_processed.drop("Age", inplace=True, axis=1)
train_processed_np = train_processed.to_numpy()
np.save("train_processed_features.npy", train_processed_np)
np.save("train_processed_target.npy", train_processed_ages)

test_processed = test_processed.assign(Age = test_annotated.T.Age)
test_processed = test_processed.sort_values("Age")
test_processed = test_processed.dropna(axis=0, how='any')

test_processed_ages = test_processed["Age"]
test_processed.drop("Age", inplace=True, axis=1)
test_processed_np = test_processed.to_numpy()
np.save("test_processed_features.npy", test_processed_np)
np.save("test_processed_target.npy", test_processed_ages)
 
# Print heatmaps
SMALL_SIZE = 18
MEDIUM_SIZE = 25
BIGGER_SIZE = 30

plt.rc('font', size=SMALL_SIZE)          # controls default text sizes
plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title
plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels
plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels
plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels
plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize
plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title


fig, (a0, a1) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [5, 1]})
fig.set_size_inches(18.5, 10.5, forward=True)

train_processed_np = np.load('X_train.npy')
test_processed_np = np.load('X_test.npy')

sns.heatmap(train_processed_np.T, annot=False, ax = a0)
a0.set_title('Heatmap of Train Methylation Values', pad=20)
a0.set_xlabel("Samples sorted ascending by age", labelpad=15)
a0.set_ylabel("25 selected cgp positions", labelpad=15)

sns.heatmap(test_processed_np.T, annot=False, ax = a1)
a1.set_title('Heatmap of Test Methylation Values', pad=20)
a1.set_xlabel("Samples sorted ascending by age", labelpad=15)
a1.set_ylabel("25 selected cgp positions", labelpad=15)

fig.tight_layout()
fig.savefig('train_test_heatmap25.jpg', dpi=100)

"""# The easy part: Keras"""

# Basic neural net with 4 dense layers
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(1024, activation='relu', input_shape=(25,)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1)
])

# Conv model
model_conv = tf.keras.models.Sequential([
  tf.keras.layers.Reshape((4, 4, 1), input_shape=(16,)),
  tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same'),
  tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same'),
  #tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.3),
  # tf.keras.layers.Dense(256, activation='relu'),
  # tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.3),
  #tf.keras.layers.Dense(2, activation='softmax')
  tf.keras.layers.Dense(1)
])

# Let me know if you are able to produce a better model!

model.compile(loss= "mean_squared_error" , optimizer="adam", metrics=["mean_squared_error"])
model.summary()
model.fit(train_processed_np, train_processed_ages,  epochs=50, validation_data=(test_processed_np, test_processed_ages))

"""# Analysis of Results"""

# for generating submission
X_test = test_processed_np
X_train = train_processed_np
y_test = test_processed_ages
y_train = train_processed_ages

np.save("X_test.npy", X_test)
np.save("X_train.npy", X_train)
y = model.predict(X_test)
y_ = model.predict(X_train)


dfd = abs(y[:, 0] - y_test)
dfc = abs(y_test.mean() - y_test)

random_array = np.random.randint(15, high=100, size=(73))
dfr = abs(random_array - y_test)

print("Tests for Plus or Minus 10 Years")
dfsum = pd.DataFrame(dfd < 10)
dfcsum = pd.DataFrame(dfc < 10)
dfrsum = pd.DataFrame(dfr < 10)

print("Machine Learning:")
print(dfsum.sum() / len(dfsum))
print("Guess Mean:")
print(dfcsum.sum() / len(dfcsum))
print("Guess Random Between 15 and 100:")
print(dfrsum.sum() / len(dfrsum))

print("Tests for Plus or Minus 5 Years")
dfsum = pd.DataFrame(dfd < 5)
dfcsum = pd.DataFrame(dfc < 5)
dfrsum = pd.DataFrame(dfr < 5)
print("Machine Learning:")
print(dfsum.sum() / len(dfsum))
print("Guess Mean:")
print(dfcsum.sum() / len(dfcsum))
print("Guess Random Between 15 and 100:")
print(dfrsum.sum() / len(dfrsum))



##  Comparing Real and Predicted Ages by Index (Validation Set)
df = pd.DataFrame({"Real":y_test, "Pred":y.reshape(73)})
df = df.sort_values(by=['Real'])
pr = plt.scatter(x = range(73), y = df.Pred, c = 'b')
re = plt.scatter(x = range(73), y = df.Real, c = 'r')
plt.xlabel('Indexes Sorted By Real Age')
plt.ylabel('Age')
plt.suptitle('Comparing Real and Predicted Ages by Index (Validation Set)')

plt.legend((pr, re),
  ('Predicted', 'Real'),
  scatterpoints=1,
  loc='upper left',
  ncol=1,
  fontsize=8)

plt.savefig('Comparing Real and Predicted Ages by Index (Validation Set)')
plt.show()

## Comparing Real and Predicted Ages by Index (Training Set)
df = pd.DataFrame({"Real":y_train, "Pred":y_.reshape(656)})
df = df.sort_values(by=['Real'])
pr = plt.scatter(x = range(656), y = df.Pred, c = 'b')
re = plt.scatter(x = range(656), y = df.Real, c = 'r')
plt.xlabel('Indexes Sorted By Real Age')
plt.ylabel('Age')
plt.suptitle('Comparing Real and Predicted Ages by Index (Training Set)')

plt.legend((pr, re),
  ('Predicted', 'Real'),
  scatterpoints=1,
  loc='upper left',
  ncol=1,
  fontsize=8)

plt.savefig('Comparing Real and Predicted Ages by Index (Training Set)')
plt.show()


## Plotting Predicted Age against Real Age (Validation Set)
plt.scatter(x=y_test, y=y.reshape(73))
np.save("y_valid_real.npy", y_test)
np.save("y_valid_pred.npy", y.reshape(73))

plt.xlabel('Real Age')
plt.ylabel('Predicted Age')
plt.suptitle('Plotting Predicted Age against Real Age (Validation Set)')

plt.savefig('Plotting Predicted Age against Real Age (Validation Set)')
plt.show()


## Plotting Predicted Age against Real Age (Training Set)
plt.scatter(x=y_train, y=y_.reshape(656), c='b')

plt.xlabel('Real Age')
plt.ylabel('Predicted Age')
plt.suptitle('Plotting Predicted Age against Real Age (Training Set)')

plt.savefig('Plotting Predicted Age against Real Age (Training Set)')
plt.show()

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import classification_report
from scipy import stats

y_true = test_processed_ages
y_pred = y.flatten()
print("Mean Absolute Error: " + str(mean_absolute_error(y_true, y_pred)))
print("Standard Error: " + str(stats.sem(y_true - y_pred)))
print("Standard Deviation: " + str(np.std(y_true - y_pred)))

"""# Saving the model for production use"""

!pip install tensorflowjs

# Save model
model.save("keras.h5")

!mkdir -p model
!tensorflowjs_converter --input_format keras keras.h5 model/

!zip -r model.zip model



!zip "$(date +%F-%M)figures.zip" X_test.npy X_train.npy train_processed_features.npy train_processed_target.npy test_processed_features.npy test_processed_target.npy train_test_heatmap25.jpg y_valid_pred.npy y_valid_real.npy "Comparing Real and Predicted Ages by Index (Training Set).png" 'Plotting Predicted Age against Real Age (Training Set).png' "Plotting Predicted Age against Real Age (Validation Set).png" "Comparing Real and Predicted Ages by Index (Validation Set).png" "Comparing Real and Predicted Ages by Index (Validation Set).png" keras.h5
np.save("train_processed_features.npy", train_processed_np)
np.save("train_processed_target.npy", train_processed_ages)

test_processed = test_processed.assign(Age = test_annotated.T.Age)
test_processed = test_processed.sort_values("Age")
test_processed = test_processed.dropna(axis=0, how='any')

test_processed_ages = test_processed["Age"]
test_processed.drop("Age", inplace=True, axis=1)
test_processed_np = test_processed.to_numpy()
np.save("test_processed_features.npy", test_processed_np)
np.save("test_processed_target.npy", test_processed_ages)

!tar -cvzf all_data.tar.gz final_matrix.csv